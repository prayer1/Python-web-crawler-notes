BeautifulSoup


import requests
from bs4 import BeautifulSoup
r = requests.get("http://python123.io/ws/demo.html")
print(r.status_code)
r.encoding = r.apparent_encoding
demo = r.text
soup = BeautifulSoup(demo, 'html.parser')
print(soup.prettify())

Beautiful Soup库解析器
soup = BeautifulSoup('<html>data</html>'，'html.parser')
解析器 				使用方法 				  条件
bs4的HTML解析器 	BeautifulSoup(mk,'html.parser') 		安装bs4库
lxml的HTML解析器 	BeautifulSoup(mk,'lxml') 			pip install lxml
lxml的XML解析器	 	BeautifulSoup(mk,'xml') 			pip install lxml		
html5lib的解析器 	BeautifulSoup(mk,'html5lib') 			pip install html5lib

Tag 标签
基本元素 	说明
Tag 		标签，最基本的信息组织单元，分别用<>和</>标明开头和结尾
任何存在于HTML语法中的标签都可以用soup.<tag>访问获得
当HTML文档中存在多个相同<tag>对应内容时，soup.<tag>返回第一个
from bs4 import BeautifulSoup
soup = BeautifulSoup(demo, 'html.parser')
>>>soup.title   #<title>This is a python demo page</title>
tag = soup.a
>>>tag      #<a class="py1" href="http://www.icout.........."  id="link1">Basic Python</a>

Tag的name（名字）
基本元素 		说明
Name 			标签的名字，<p>…</p>的名字是'p'，格式：<tag>.name
>>> soup.a.name
'a'
>>> soup.a.parent.name
'p'
>>> soup.a.parent.parent.name
'body'
每个<tag>都有自己的名字，通过<tag>.name获取，字符串类型

Tag的attrs（属性）
基本元素 		说明
Attributes 		标签的属性，字典形式组织，格式：<tag>.attrs
>>> tag = soup.a
>>> tag.attrs
{'href': 'http://www.icourse163.org/course/BIT-268001', 'class': ['py1'], 'id': 'link1'}
>>> tag.attrs['class']
['py1']
>>> tag.attrs['href']
'http://www.icourse163.org/course/BIT-268001'
>>> type(tag.attrs)
<class 'dict'>
>>> type(tag)
<class 'bs4.element.Tag'>

Tag的NavigableString
基本元素 		说明
NavigableString 	标签内非属性字符串，<>…</>中字符串，格式：<tag>.string
NavigableString		可以跨越多个层次
>>> soup.a
<a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a>
>>> soup.a.string
'Basic Python'
>>> soup.p
<p class="title"><b>The demo python introduces several python courses.</b></p>
>>> soup.p.string
'The demo python introduces several python courses.'
>>> type(soup.p.string)
<class 'bs4.element.NavigableString'>
一个<tag>可以有0或多个属性，字典类型

Tag的Comment
基本元素 		说明
Comment 	标签内字符串的注释部分，一种特殊的Comment类型
newsoup = BeautifulSoup("<b><!--This is a comment--></b><p>This is not  </p>", "html.parser")
>>> newsoup.b.string
'This is a comment'
>>> type(newsoup.b.string)
<class 'bs4.element.Comment'>
>>> newsoup.p.string
'This is not  '
>>> type(newsoup.b.string)
<class 'bs4.element.Comment'>

BeautifulSoup类的基本元素
<p class=“title”> … </p>
基本元素 			说明
Tag		 标签，最基本的信息组织单元，分别用<>和</>标明开头和结尾
Name 		 标签的名字，<p>…</p>的名字是'p'，格式：<tag>.name
Attributes 	 标签的属性，字典形式组织，格式：<tag>.attrs
NavigableString  标签内非属性字符串，<>…</>中字符串，格式：<tag>.string
Comment 	 标签内字符串的注释部分，一种特殊的Comment类型

基于bs4库的HTML内容遍历方法

标签树的下行遍历
属性 				说明
.contents 	子节点的列表，将<tag>所有儿子节点存入列表
.children 	子节点的迭代类型，与.contents类似，用于循环遍历儿子节点
.descendants 	子孙节点的迭代类型，包含所有子孙节点，用于循环遍历
BeautifulSoup类型是标签树的根节点

标签树的上行遍历
属性 			说明
.parent 	节点的父亲标签
.parents 	节点先辈标签的迭代类型，用于循环遍历先辈节点

标签树的平行遍历
属性 				说明
.next_sibling 		返回按照HTML文本顺序的下一个平行节点标签
.previous_sibling 	返回按照HTML文本顺序的上一个平行节点标签
.next_siblings 		迭代类型，返回按照HTML文本顺序的后续所有平行节点标签
.previous_siblings 	迭代类型，返回按照HTML文本顺序的前续所有平行节点标签

基于bs4库的HTML格式输出

bs4库的prettify()方法
import requests
from bs4 import BeautifulSoup
r = requests.get("http://python123.io/ws/demo.html")
demo = r.text
soup = BeautifulSoup(demo, 'html.parser')
print(soup.prettify())

bs4库的prettify()方法
.prettify()为HTML文本<>及其内容增加更加'\n'
.prettify()可用于标签，方法：<tag>.prettify()
>>>print(soup.pretty())
<a class="py1' href="http://www.icourse163.org/course/BIT268001" id="link1">
Basic Python
</a>

bs4库的编码
bs4库将任何HTML输入都变成utf\8编码
Python 3.x默认支持编码是utf\8,解析无障碍

基于bs4库的HTML内容查找方法

import requests
from bs4 import BeautifulSoup
r = requests.get("http://python123.io/ws/demo.html")
temo = r.text
soup = BeautifulSoup(temo, "html.parser")
print(soup.find_all('a'))
print(soup.find_all(['a', 'b']))


<>.find_all(name, attrs, recursive, string, **kwargs)
? name : 对标签名称的检索字符串
返回一个列表类型，存储查找的结果
import requests
from bs4 import BeautifulSoup
r = requests.get("http://python123.io/ws/demo.html")
temo = r.text
soup = BeautifulSoup(temo, "html.parser")
print(soup.find_all('a'))
print(soup.find_all(['a', 'b']))
for tag in soup.find_all(True):
    print(tag.name)
import re
for tag in soup.find_all(re.compile('b')):
    print(tag.name)